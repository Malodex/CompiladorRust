PARSER_BEGIN(RustLexer)
import java.io.FileWriter;
import java.io.IOException;
import java.lang.reflect.Field;
import java.util.HashMap;

public class RustLexer {
    public static HashMap<Integer, String> tokenNames;

    public static void initializeTokenNames() {
        tokenNames = new HashMap<Integer, String>();
        Field[] fields = RustLexerConstants.class.getDeclaredFields();
        for (Field field : fields) {
            if (field.getType() == int.class) {
                try {
                    int value = field.getInt(null);
                    String name = field.getName();
                    tokenNames.put(value, name);
                } catch (IllegalAccessException e) {
                    e.printStackTrace();
                }
            }
        }
    }

    public static void main(String[] args) throws ParseException, IOException {
        RustLexer parser = new RustLexer(System.in);
        initializeTokenNames();
        FileWriter writer = new FileWriter("saida_csharp_tokens.txt");

        while (true) {
            Token t = parser.getNextToken();
            if (t.kind == EOF) break;
            String tokenName = tokenNames.get(t.kind);
            String output = tokenName + " " + t.image;
            System.out.println(output);
            writer.write(output + "\n");
        }
        writer.close();
    }
}

PARSER_END(RustLexer)
  
  TOKEN_MGR_DECLS : {
    // Declarações adicionais para o gerenciador de tokens, se necessário
  }
  
SKIP: {
    " " | "\t" | "\n" | "\r" | "U+000B" | "U+000C" | "U+000D" | "U+200E" |  "U+200F" | "U+0020"  | "U+2028" | "U+2029"| "U+0085"
}
  
  TOKEN : {
    <LET: "let"> |
    <MUT: "mut"> |
    <FN: "fn"> |
    <IDENTIFIER: ["a"-"z", "A"-"Z", "_"] (["a"-"z", "A"-"Z", "0"-"9", "_"])*> |
    <NUMBER: ["0"-"9"] (["0"-"9"])*>
  }
  
  TOKEN : {
    <PLUS: "+"> |
    <MINUS: "-"> |
    <STAR: "*"> |
    <SLASH: "/"> |
    <EQ: "="> |
    <SEMI: ";">
  }
  